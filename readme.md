# [WORK IN PROGRASS] ANFIS Tensoflow 2.0
A simple implementation of [Adaptive-Network-Based Fuzzy Inference System (ANFIS)](https://www.researchgate.net/publication/3113825_ANFIS_Adaptive-Network-based_Fuzzy_Inference_System) based on [Tensorflow 2.0](https://www.tensorflow.org/guide) and [Keras](https://keras.io/). 

## 1. Features
#### Model
Currently the implementation will support two types of membership functions (```memb_func```):
- gaussian
- generalized bell 

In contrast to the original paper, you can choose
- [optimizers](https://keras.io/optimizers/) (```optimzer```) 
- and [loss functions](https://keras.io/losses/) (```loss_func```)
from the keras toolbox documentation.

No. of membership functions ```n_memb```, input size of the network ```n_input``` and number of learning epochs ```n_epochs``` can be set abitrarily. 
#### Sandbox
The sandbox `run_anfis.py` includes six default data sets `data_set` (1-6) to fit:
1. markov regime switching time series
2. chaotic time series generated by the Mackey-Glass differential delay equation (taken from the paper)
3. Two-Input Nonlinear Function, e.g. sinc equation (taken from the paper)
4. Three-Input Nonlinear Functnion (taken from the paper)
5. [diabetes dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_diabetes.html)  from scikit learn
6. artificial [reggresion-type problem](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_regression.html) from skikit learn

You can choose from various parameters to set inputs, membershipfunctions, losses and optimizers as well as evaluation metrics. 

#### Experimental Setup
For [hyperparameter tuning](https://www.tensorflow.org/tensorboard/hyperparameter_tuning_with_hparams) you can run `exp_anfis.py` which tunes `n_input`, `n_memb`, `memb_func`, `loss` and `optimizer` depending an arbitrary metric and data set. The experiment also includes a callback for [Tensorboard](https://www.tensorflow.org/tensorboard) (see 4. Using Tensorboard).
## 2. Dependencies

- Python 3.5-3.7
- tensorflow 2.0.0 (or higher)
- numpy (1.18.1)
- matplotlib (3.1.3)
- pandas (1.0.1)
- sklearn (0.22.1)
- seaborn (0.10.0)

To install requirements,  `cd` to the directory of the repository and run `pip install -r requirements.txt`. A virtual environment is recommended. 

## 3. Quickstart
A quick start to a default ANFIS model is shown below. `myanfis.ANFIS()` is a [customized](https://www.tensorflow.org/guide/keras/custom_layers_and_models) tensorflow model. As a consequence you can use all model functions that are part of tensorflow, i.e. `model.compile()` to compile the model.

```python
import myanfis
import data_gen as gen
import tensorflow as tf

param_obj = myanfis.fis_parameters(n_input=4, n_memb=3)    

X, X_train, X_test, y, y_train, y_test = sim.gen_data(data_set=2,       # pick a data set (mackey)
                                                        n_obs=2080,     # length of data set
                                                        param.n_input ) # number of lagged inputs
                                                        
fis = myanfis.ANFIS(n_input = param.n_input,        
                    n_memb = param.n_memb, 
                    batch_size = param.batch_size, 
                    memb_func = param.memb_func,
                    name = 'myanfis' )

fis.model.compile(optimizer=param.optimizer, 
                  loss=param.loss 
                  ,metrics=['mae', 'mse'] )

history = fis.fit(X_train, y_train, 
                  epochs=param.n_epochs, 
                  batch_size=param.batch_size,
                  validation_data = (X_test, y_test) )  
```
You can use various plots to visualize results i.e. show fitted outcome vs. the true values:
```python
if plot_prediction:
    y_pred = fis.model.predict(X)
    f, axs = plt.subplots(2,1,figsize=(8,10))
    f.suptitle('Mackey time series', size=16)
    axs[0].plot(y)
    axs[0].plot(y_pred, alpha=.7)
    axs[0].legend(['Real', 'Predicted'])
    axs[0].grid(True)
    axs[0].set_title('Real vs. Predicted values')
    axs[1].plot(np.arange(y.shape[0]), y - y_pred)
    axs[1].legend(['pred_error'])
    axs[1].grid(True)
    axs[1].set_title('Prediction Error')
    plt.show()
```
![fitted_vs_true_values](https://raw.githubusercontent.com/gregorLen/MyAnfis/master/imgs/predictions.png?token=ALUKURIVSU56AKVY2V7H6LK6TVWG2)



Plotting the membershipfunctions is part of the ANFIS class:
```python
if plot_mfs:
    fis.plotmfs()

```
![plot membership functions](https://raw.githubusercontent.com/gregorLen/MyAnfis/master/imgs/memb_funcs.png?token=ALUKURJLOG5V44WOITIWZ2C6TVWGQ)
Or learning curves:
```python
if plot_learningcurves:
    loss_curves = pd.DataFrame(history.history)
    loss_curves.plot(figsize=(8, 5))
    plt.grid(True)
    plt.show()
``` 
![plot learning curves](https://raw.githubusercontent.com/gregorLen/MyAnfis/master/imgs/learning_curves.png?token=ALUKURMCJLQKGVXTFR4X4BK6TVWGI)




---
## 4. Using Tensorboard
Tensorboard provides visualization and tooling needed for machine learning experimentation. Further information can be found [here](https://www.tensorflow.org/tensorboard)
#### Step 0: Define a callback in code
```python
log_name = f'-data_{data_set}_N{param.n_input}_M{param.n_memb}_batch{param.batch_size}_{param.memb_func}_{param.optimizer}_{param.loss}'

log_path = os.path.join("logs", 
                    datetime.datetime.now().strftime("%Y%m%d-%H%M%S") + log_name )

tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_path, histogram_freq=1)

history = fis.fit(...
                  callbacks = [tensorboard_callback] )  

```



#### Step 1: Set working directory : 
- i.e. for windows ```cd ...\...\MyAnfis```  

#### Step 2: Activate virtual environment
- ```conda activate tensorflow```

#### Step 3: Start Tensorboard
- for single runs ``` tensorboard --logdir=logs/run_anfis ```
- for an experimental session ```tensorboard --logdir=logs/exp_anfis```

#### Step 4: Open Browser
>> localhost:6006
---
## 5. TO DO
- sigmoid membership function
## 6. Related Work
- [bare-bones implementation of ANFIS](https://github.com/twmeggs/anfis) (manual derivatives) by [twmeggs](https://github.com/twmeggs) 
- [PyTorch implementation](https://github.com/jfpower/anfis-pytorch) by [James Power](http://www.cs.nuim.ie/~jpower/)
- [simple ANFIS based on Tensorflow 1.15.2](https://github.com/tiagoCuervo/TensorANFIS) by [Santiago Cuervo](https://github.com/tiagoCuervo)
---
## 7. Contact
I am very thankful for any kind of feedback. Also, if you have questions, please contact gregor.lenhard@unibas.ch